"""
å¤šæ¨¡æ€å¼‚å¸¸æ£€æµ‹Transformeræ¼”ç¤ºè„šæœ¬
å±•ç¤ºå¦‚ä½•ä½¿ç”¨ç»Ÿä¸€æ¶æ„åŒæ—¶å¤„ç†å›¾åƒå’Œæ•°å€¼å¼‚å¸¸æ£€æµ‹
"""

import torch
import numpy as np
from sklearn.metrics import roc_auc_score, precision_recall_fscore_support, accuracy_score
import os
import argparse
import time
from typing import Dict, Any
from torch.utils.data import DataLoader
from tqdm import tqdm

from multimodal_anomaly_detector import (
    MultiModalAnomalyTransformer, Trainer, load_image_anomaly_data,
    load_thyroid_data, create_dataloaders, MultiModalDataset
)
from config import get_config, get_small_config, get_large_config
from visualization import AnomalyVisualizer
from logger import setup_experiment_logging, BatchTimer


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='å¤šæ¨¡æ€å¼‚å¸¸æ£€æµ‹Transformeræ¼”ç¤º')

    parser.add_argument('--config', type=str, default='default',
                       choices=['small', 'default', 'large'],
                       help='æ¨¡å‹é…ç½®å¤§å°')
    parser.add_argument('--epochs', type=int, default=None,
                       help='è®­ç»ƒè½®æ•°ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰')
    parser.add_argument('--batch_size', type=int, default=None,
                       help='æ‰¹æ¬¡å¤§å°ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰')
    parser.add_argument('--device', type=str, default='auto',
                       choices=['auto', 'cuda', 'cpu'],
                       help='è®¡ç®—è®¾å¤‡')
    parser.add_argument('--save_dir', type=str, default='results',
                       help='ç»“æœä¿å­˜ç›®å½•')
    parser.add_argument('--quick_test', action='store_true',
                       help='å¿«é€Ÿæµ‹è¯•æ¨¡å¼ï¼ˆå‡å°‘è®­ç»ƒè½®æ•°ï¼‰')
    parser.add_argument('--resume', type=str, default=None,
                       help='ä»checkpointç»§ç»­è®­ç»ƒçš„è·¯å¾„')

    return parser.parse_args()


def setup_device(device_str: str):
    """è®¾ç½®è®¡ç®—è®¾å¤‡"""
    if device_str == 'auto':
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    else:
        device = torch.device(device_str)

    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    if device.type == 'cuda':
        print(f"GPUå‹å·: {torch.cuda.get_device_name(device)}")
        print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")

    return device


def load_data(config):
    """åŠ è½½æ•°æ®"""
    print("åŠ è½½æ•°æ®...")

    # åŠ è½½å›¾åƒæ•°æ®
    image_train_paths, image_test_paths, image_test_labels = load_image_anomaly_data(
        config.image_data_path, config.image_category, config.train_normal_only
    )

    # åŠ è½½æ•°å€¼æ•°æ®
    numerical_train_data, numerical_test_data, numerical_test_labels = load_thyroid_data(
        config.thyroid_data_path
    )

    print("æ•°æ®é›†ç»Ÿè®¡:")
    print(f"  å›¾åƒè®­ç»ƒæ ·æœ¬: {len(image_train_paths)} (ä»…æ­£å¸¸æ ·æœ¬)")
    print(f"  å›¾åƒæµ‹è¯•æ ·æœ¬: {len(image_test_paths)}")
    print(f"  æ•°å€¼è®­ç»ƒæ ·æœ¬: {len(numerical_train_data)} (ä»…æ­£å¸¸æ ·æœ¬)")
    print(f"  æ•°å€¼æµ‹è¯•æ ·æœ¬: {len(numerical_test_data)}")

    # è®¡ç®—å¼‚å¸¸æ¯”ä¾‹
    image_anomaly_ratio = sum(image_test_labels) / len(image_test_labels) if image_test_labels else 0
    numerical_anomaly_ratio = sum(numerical_test_labels) / len(numerical_test_labels)

    print(".2%")
    print(".2%")

    return (image_train_paths, image_test_paths, image_test_labels,
            numerical_train_data, numerical_test_data, numerical_test_labels)


def create_model_and_trainer(model_config, training_config, device):
    """åˆ›å»ºæ¨¡å‹å’Œè®­ç»ƒå™¨"""
    print("åˆ›å»ºæ¨¡å‹...")

    model = MultiModalAnomalyTransformer(
        img_size=model_config.img_size,
        patch_size=model_config.patch_size,
        in_chans=model_config.in_chans,
        num_numerical_features=model_config.num_numerical_features,
        embed_dim=model_config.embed_dim,
        depth=model_config.depth,
        num_heads=model_config.num_heads,
        mlp_ratio=model_config.mlp_ratio,
        qkv_bias=model_config.qkv_bias,
        drop_rate=model_config.drop_rate,
        attn_drop_rate=model_config.attn_drop_rate
    )

    # ç»Ÿè®¡å‚æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

    print(f"ğŸ“ æ¨¡å‹ä¿¡æ¯:")
    print(f"  æ€»å‚æ•°é‡: {total_params:,}")
    print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")

    trainer = Trainer(model, device)
    trainer.optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=training_config.learning_rate,
        weight_decay=training_config.weight_decay
    )
    trainer.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        trainer.optimizer, T_max=training_config.num_epochs
    )

    return model, trainer


def train_model(trainer, train_loader, num_epochs, save_dir):
    """è®­ç»ƒæ¨¡å‹"""
    print("ğŸš€ å¼€å§‹è®­ç»ƒ...")

    train_losses = []
    val_aucs = []

    for epoch in range(num_epochs):
        # è®­ç»ƒä¸€ä¸ªepoch
        train_loss = trainer.train_epoch(train_loader)
        train_losses.append(train_loss)

        print("2d")

        # æ¯5ä¸ªepochè¿›è¡Œä¸€æ¬¡éªŒè¯
        if (epoch + 1) % 5 == 0:
            try:
                # è¿™é‡Œå¯ä»¥æ·»åŠ éªŒè¯é€»è¾‘
                val_auc = 0.0  # æš‚æ—¶è®¾ä¸º0
                val_aucs.append(val_auc)
            except:
                val_aucs.append(0.0)

    print("è®­ç»ƒå®Œæˆï¼")
    return train_losses, val_aucs


def evaluate_model(trainer, test_loader, visualizer, threshold_percentile=95.0):
    """è¯„ä¼°æ¨¡å‹"""
    print("è¯„ä¼°æ¨¡å‹...")

    # è·å–é¢„æµ‹åˆ†æ•°
    scores, labels = trainer.evaluate(test_loader)

    # è®¡ç®—AUC
    auc_score = roc_auc_score(labels, scores)

    # è®¡ç®—æœ€ä½³é˜ˆå€¼å’Œé¢„æµ‹ç»“æœ
    threshold = np.percentile(scores, threshold_percentile)
    predictions = (scores > threshold).astype(int)

    # è®¡ç®—åˆ†ç±»æŒ‡æ ‡
    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')
    accuracy = accuracy_score(labels, predictions)


    # å¯è§†åŒ–ç»“æœ
    print("ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")

    visualizer.plot_anomaly_scores(scores, labels)
    auc_val, optimal_threshold = visualizer.plot_roc_curve(labels, scores)
    ap_score = visualizer.plot_precision_recall_curve(labels, scores)

    # ä½¿ç”¨æœ€ä½³é˜ˆå€¼é‡æ–°è®¡ç®—é¢„æµ‹ç»“æœ
    optimal_predictions = (scores > optimal_threshold).astype(int)
    visualizer.plot_confusion_matrix(labels, optimal_predictions)

    # è®¡ç®—æœ€ä½³é˜ˆå€¼ä¸‹çš„æŒ‡æ ‡
    opt_precision, opt_recall, opt_f1, _ = precision_recall_fscore_support(
        labels, optimal_predictions, average='binary'
    )
    opt_accuracy = accuracy_score(labels, optimal_predictions)


    return {
        'auc': auc_score,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'accuracy': accuracy,
        'optimal_threshold': optimal_threshold,
        'used_threshold': threshold,
        'ap_score': ap_score,
        'opt_precision': opt_precision,
        'opt_recall': opt_recall,
        'opt_f1': opt_f1,
        'opt_accuracy': opt_accuracy,
        'scores': scores,
        'labels': labels,
        'predictions': predictions,
        'optimal_predictions': optimal_predictions
    }


def save_results(results: Dict[str, Any], config, save_dir: str):
    """ä¿å­˜ç»“æœ"""
    os.makedirs(save_dir, exist_ok=True)

    # ä¿å­˜æ¨¡å‹
    torch.save({
        'model_state_dict': results['model'].state_dict(),
        'config': config,
        'task_results': results.get('task_results', {})
    }, os.path.join(save_dir, 'model_checkpoint.pth'))

    # ä¿å­˜é…ç½®
    with open(os.path.join(save_dir, 'config.txt'), 'w') as f:
        f.write("æ¨¡å‹é…ç½®:\n")
        for key, value in vars(config).items():
            f.write(f"  {key}: {value}\n")

    print(f"ç»“æœå·²ä¿å­˜åˆ°: {save_dir}")


def train_task_separately(trainer, image_train_loader, numerical_train_loader, image_val_loader, numerical_val_loader, num_epochs, save_dir):
    """åˆ†åˆ«è®­ç»ƒä¸¤ç§ä»»åŠ¡"""
    print("åˆ†åˆ«è®­ç»ƒTask2å’ŒTask4...")
    print("=" * 50)

    # è®¾ç½®æ—¥å¿—è®°å½•å™¨
    logger = setup_experiment_logging(save_dir, f"multimodal_training_{time.strftime('%Y%m%d_%H%M%S')}")
    batch_timer = BatchTimer()

    # åˆå§‹åŒ–æœ€ä½³æ¨¡å‹è·Ÿè¸ª
    best_task2_auc = 0.0
    best_task4_auc = 0.0
    best_combined_auc = 0.0
    best_epoch = 0

    # è®°å½•è®­ç»ƒé…ç½®
    train_config = {
        "num_epochs": num_epochs,
        "image_train_batches": len(image_train_loader) if image_train_loader else 0,
        "numerical_train_batches": len(numerical_train_loader) if numerical_train_loader else 0,
        "image_val_batches": len(image_val_loader) if image_val_loader else 0,
        "numerical_val_batches": len(numerical_val_loader) if numerical_val_loader else 0,
        "learning_rate": trainer.optimizer.param_groups[0]['lr']
    }
    logger.log_config(train_config)

    all_train_losses = []

    # äº¤æ›¿è®­ç»ƒä¸¤ç§æ¨¡æ€
    for epoch in range(num_epochs):
        epoch_losses = []
        batch_timer.reset()

        logger.log_epoch_start(epoch, num_epochs)

        # è®¾ç½®è®­ç»ƒè½®æ¬¡å¹³è¡¡ï¼ˆå›¾åƒæ•°æ®é‡å°‘ï¼Œå¤šè®­ç»ƒå‡ è½®ï¼‰
        image_epochs = 2  # å›¾åƒä»»åŠ¡è®­ç»ƒ1è½®ï¼ˆæ¯ä¸ªepochè®­ç»ƒä¸€æ¬¡ï¼‰
        numerical_epochs = 1  # æ•°å€¼ä»»åŠ¡è®­ç»ƒ1è½®

        logger.log_info(f"Epoch {epoch + 1}: å›¾åƒè®­ç»ƒè½®æ¬¡={image_epochs}, æ•°å€¼è®­ç»ƒè½®æ¬¡={numerical_epochs}")

        # è®­ç»ƒTask2ï¼šå›¾åƒå¼‚å¸¸æ£€æµ‹
        logger.log_task_start("Task2å›¾åƒè®­ç»ƒ", f"Epoch {epoch + 1}")

        image_batch_losses = []
        if image_train_loader:
            for epoch_i in range(image_epochs):
                for batch_idx, batch in enumerate(tqdm(image_train_loader, desc=f"    å›¾åƒè½®æ¬¡{epoch_i+1}", leave=False)):
                    trainer.optimizer.zero_grad()

                    image_data = batch.get('image').to(trainer.device) if batch.get('image') is not None else None

                    reconstruction_loss, anomaly_score, _, _ = trainer.model(image_data=image_data)
                    loss = reconstruction_loss.mean() + anomaly_score.mean()

                    loss.backward()
                    trainer.optimizer.step()

                    loss_val = loss.item()
                    epoch_losses.append(loss_val)
                    image_batch_losses.append(loss_val)

        avg_image_loss = sum(image_batch_losses) / len(image_batch_losses) if image_batch_losses else 0.0
        logger.log_task_end("Task2å›¾åƒè®­ç»ƒ", results={"avg_loss": avg_image_loss, "epochs": image_epochs})

        # è®­ç»ƒTask4ï¼šæ•°å€¼å¼‚å¸¸æ£€æµ‹
        logger.log_task_start("Task4æ•°å€¼è®­ç»ƒ", f"Epoch {epoch + 1}")

        numerical_batch_losses = []
        if numerical_train_loader:
            for epoch_i in range(numerical_epochs):
                for batch_idx, batch in enumerate(tqdm(numerical_train_loader, desc=f"    æ•°å€¼è½®æ¬¡{epoch_i+1}", leave=False)):
                    trainer.optimizer.zero_grad()

                    numerical_data = batch.get('numerical').to(trainer.device) if batch.get('numerical') is not None else None

                    reconstruction_loss, anomaly_score, _, _ = trainer.model(numerical_data=numerical_data)
                    loss = reconstruction_loss.mean() + anomaly_score.mean()

                    loss.backward()
                    trainer.optimizer.step()

                    loss_val = loss.item()
                    epoch_losses.append(loss_val)
                    numerical_batch_losses.append(loss_val)

        avg_numerical_loss = sum(numerical_batch_losses) / len(numerical_batch_losses) if numerical_batch_losses else 0.0
        logger.log_task_end("Task4æ•°å€¼è®­ç»ƒ", results={"avg_loss": avg_numerical_loss, "epochs": numerical_epochs})

        # è®¡ç®—å¹³å‡è®­ç»ƒæŸå¤±
        avg_train_loss = sum(epoch_losses) / len(epoch_losses) if epoch_losses else 0.0
        all_train_losses.append(avg_train_loss)

        # è·å–å½“å‰å­¦ä¹ ç‡
        current_lr = trainer.optimizer.param_groups[0]['lr']

        # è®°å½•epochæ€»ç»“

        logger.log_epoch_summary(epoch, avg_train_loss, lr=current_lr,
                               image_loss=avg_image_loss, numerical_loss=avg_numerical_loss)

        # æ¯ä¸ªepochç»“æŸéƒ½è¿›è¡ŒéªŒè¯é›†è¯„ä¼°
        logger.log_info(f"Epoch {epoch + 1} éªŒè¯è¯„ä¼°å¼€å§‹...")

        # è¯„ä¼°Task2ï¼šå›¾åƒå¼‚å¸¸æ£€æµ‹
        task2_val_auc = 0.0
        if image_val_loader:
            image_val_scores, image_val_labels = trainer.evaluate(image_val_loader)
            if len(image_val_scores) > 0:
                image_val_auc = roc_auc_score(image_val_labels, image_val_scores)
                task2_val_auc = image_val_auc
                image_val_threshold = np.percentile(image_val_scores, 95.0)
                image_val_predictions = (image_val_scores > image_val_threshold).astype(int)
                image_val_precision, image_val_recall, image_val_f1, _ = precision_recall_fscore_support(image_val_labels, image_val_predictions, average='binary')
                image_val_accuracy = accuracy_score(image_val_labels, image_val_predictions)

                logger.log_info(f"Task2éªŒè¯ - AUC: {image_val_auc:.4f}, Precision: {image_val_precision:.4f}, Recall: {image_val_recall:.4f}, F1: {image_val_f1:.4f}, Acc: {image_val_accuracy:.4f}")

        # è¯„ä¼°Task4ï¼šæ•°å€¼å¼‚å¸¸æ£€æµ‹
        task4_val_auc = 0.0
        if numerical_val_loader:
            numerical_val_scores, numerical_val_labels = trainer.evaluate(numerical_val_loader)
            if len(numerical_val_scores) > 0:
                numerical_val_auc = roc_auc_score(numerical_val_labels, numerical_val_scores)
                task4_val_auc = numerical_val_auc
                numerical_val_threshold = np.percentile(numerical_val_scores, 95.0)
                numerical_val_predictions = (numerical_val_scores > numerical_val_threshold).astype(int)
                numerical_val_precision, numerical_val_recall, numerical_val_f1, _ = precision_recall_fscore_support(numerical_val_labels, numerical_val_predictions, average='binary')
                numerical_val_accuracy = accuracy_score(numerical_val_labels, numerical_val_predictions)

                logger.log_info(f"Task4éªŒè¯ - AUC: {numerical_val_auc:.4f}, Precision: {numerical_val_precision:.4f}, Recall: {numerical_val_recall:.4f}, F1: {numerical_val_f1:.4f}, Acc: {numerical_val_accuracy:.4f}")

        # æ£€æŸ¥æ˜¯å¦ä¸ºæœ€ä½³æ¨¡å‹å¹¶ä¿å­˜
        current_combined_auc = (task2_val_auc + task4_val_auc) / 2

        if current_combined_auc > best_combined_auc:
            best_task2_auc = task2_val_auc
            best_task4_auc = task4_val_auc
            best_combined_auc = current_combined_auc
            best_epoch = epoch + 1

            # ä¿å­˜æœ€ä½³æ¨¡å‹
            best_model_path = os.path.join(save_dir, 'best_model_checkpoint.pth')
            torch.save({
                'model_state_dict': trainer.model.state_dict(),
                'optimizer_state_dict': trainer.optimizer.state_dict(),
                'epoch': epoch + 1,
                'best_task2_auc': best_task2_auc,
                'best_task4_auc': best_task4_auc,
                'best_combined_auc': best_combined_auc,
                'config': trainer.model_config if hasattr(trainer, 'model_config') else None
            }, best_model_path)

            logger.log_info(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ - Epoch {epoch + 1}, ç»„åˆAUC: {best_combined_auc:.4f} (Task2: {best_task2_auc:.4f}, Task4: {best_task4_auc:.4f})")

        logger.log_info(f"Epoch {epoch + 1} éªŒè¯è¯„ä¼°å®Œæˆ")

        # å­¦ä¹ ç‡è°ƒåº¦
        trainer.scheduler.step()

        # æ›´æ–°å­¦ä¹ ç‡æ˜¾ç¤º
        new_lr = trainer.optimizer.param_groups[0]['lr']
        if abs(new_lr - current_lr) > 1e-8:
            logger.log_info(".6f")

    # è®°å½•æœ€ç»ˆç»“æœ
    final_results = {
        'final_train_loss': all_train_losses[-1] if all_train_losses else 0.0,
        'total_epochs': num_epochs,
        'best_epoch': best_epoch,
        'best_task2_auc': best_task2_auc,
        'best_task4_auc': best_task4_auc,
        'best_combined_auc': best_combined_auc
    }
    logger.log_task_end("æ•´ä½“è®­ç»ƒ", results=final_results)
    logger.close()

    print("åˆ†åˆ«è®­ç»ƒå®Œæˆï¼è¯¦ç»†æ—¥å¿—å·²ä¿å­˜ã€‚")
    return all_train_losses, []


def evaluate_separate_tasks(trainer, image_test_loader, numerical_test_loader, visualizer, threshold_percentile=95.0):
    """åˆ†åˆ«è¯„ä¼°ä¸¤ç§ä»»åŠ¡"""
    print("åˆ†åˆ«è¯„ä¼°Task2å’ŒTask4...")

    # è®¾ç½®è¯„ä¼°æ—¥å¿—
    eval_logger = setup_experiment_logging("results", "evaluation")

    results = {}

    # è¯„ä¼°Task2ï¼šå›¾åƒå¼‚å¸¸æ£€æµ‹
    eval_logger.log_task_start("Task2å›¾åƒè¯„ä¼°", f"æµ‹è¯•æ ·æœ¬æ•°: {len(image_test_loader.dataset) if image_test_loader else 0}")
    print("è¯„ä¼°Task2ï¼ˆå›¾åƒå¼‚å¸¸æ£€æµ‹ï¼‰...")
    image_scores, image_labels = trainer.evaluate(image_test_loader)

    if len(image_scores) > 0:
        image_auc = roc_auc_score(image_labels, image_scores)
        image_threshold = np.percentile(image_scores, threshold_percentile)
        image_predictions = (image_scores > image_threshold).astype(int)
        image_precision, image_recall, image_f1, _ = precision_recall_fscore_support(image_labels, image_predictions, average='binary')
        image_accuracy = accuracy_score(image_labels, image_predictions)

        task2_metrics = {
            'auc': image_auc,
            'precision': image_precision,
            'recall': image_recall,
            'f1': image_f1,
            'accuracy': image_accuracy,
            'threshold': image_threshold
        }

        results['task2'] = {
            **task2_metrics,
            'scores': image_scores,
            'labels': image_labels,
            'predictions': image_predictions
        }

        # è®°å½•è¯„ä¼°ç»“æœåˆ°æ—¥å¿—
        eval_logger.log_evaluation_results("Task2å›¾åƒå¼‚å¸¸æ£€æµ‹", task2_metrics)

        # å¯è§†åŒ–Task2ç»“æœ
        visualizer.plot_anomaly_scores(image_scores, image_labels, title="Task2: å›¾åƒå¼‚å¸¸æ£€æµ‹ç»“æœ", save_name="task2_anomaly_scores.png")
        visualizer.plot_roc_curve(image_labels, image_scores, title="Task2: å›¾åƒå¼‚å¸¸æ£€æµ‹ROCæ›²çº¿", save_name="task2_roc_curve.png")

    eval_logger.log_task_end("Task2å›¾åƒè¯„ä¼°")

    # è¯„ä¼°Task4ï¼šæ•°å€¼å¼‚å¸¸æ£€æµ‹
    eval_logger.log_task_start("Task4æ•°å€¼è¯„ä¼°", f"æµ‹è¯•æ ·æœ¬æ•°: {len(numerical_test_loader.dataset) if numerical_test_loader else 0}")
    print("è¯„ä¼°Task4ï¼ˆæ•°å€¼å¼‚å¸¸æ£€æµ‹ï¼‰...")
    numerical_scores, numerical_labels = trainer.evaluate(numerical_test_loader)

    if len(numerical_scores) > 0:
        numerical_auc = roc_auc_score(numerical_labels, numerical_scores)

        numerical_threshold = np.percentile(numerical_scores, threshold_percentile)
        numerical_predictions = (numerical_scores > numerical_threshold).astype(int)
        numerical_precision, numerical_recall, numerical_f1, _ = precision_recall_fscore_support(numerical_labels, numerical_predictions, average='binary')
        numerical_accuracy = accuracy_score(numerical_labels, numerical_predictions)

        task4_metrics = {
            'auc': numerical_auc,
            'precision': numerical_precision,
            'recall': numerical_recall,
            'f1': numerical_f1,
            'accuracy': numerical_accuracy,
            'threshold': numerical_threshold
        }

        results['task4'] = {
            **task4_metrics,
            'scores': numerical_scores,
            'labels': numerical_labels,
            'predictions': numerical_predictions
        }

        # è®°å½•è¯„ä¼°ç»“æœåˆ°æ—¥å¿—
        eval_logger.log_evaluation_results("Task4æ•°å€¼å¼‚å¸¸æ£€æµ‹", task4_metrics)

        # å¯è§†åŒ–Task4ç»“æœ
        visualizer.plot_anomaly_scores(numerical_scores, numerical_labels, title="Task4: æ•°å€¼å¼‚å¸¸æ£€æµ‹ç»“æœ", save_name="task4_anomaly_scores.png")
        visualizer.plot_roc_curve(numerical_labels, numerical_scores, title="Task4: æ•°å€¼å¼‚å¸¸æ£€æµ‹ROCæ›²çº¿", save_name="task4_roc_curve.png")

    eval_logger.log_task_end("Task4æ•°å€¼è¯„ä¼°")
    eval_logger.close()

    return results


def create_separate_dataloaders(image_train_paths, image_test_paths, image_test_labels,
                               numerical_train_data, numerical_test_data, numerical_test_labels,
                               batch_size=8, val_split=0.2):
    """åˆ›å»ºåˆ†åˆ«çš„æ•°æ®åŠ è½½å™¨

    æ³¨æ„ï¼šå¯¹äºå¼‚å¸¸æ£€æµ‹ä»»åŠ¡ï¼ŒéªŒè¯é›†ä»æµ‹è¯•é›†ä¸­åˆ’åˆ†ï¼Œå› ä¸ºè®­ç»ƒé›†åªåŒ…å«æ­£å¸¸æ ·æœ¬
    """
    from torchvision import transforms
    from sklearn.model_selection import train_test_split

    # å›¾åƒå˜æ¢
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    # Task2æ•°æ®åŠ è½½å™¨ï¼ˆå›¾åƒï¼‰
    image_train_loader = None
    image_val_loader = None
    image_test_loader = None

    if image_train_paths:
        # è®­ç»ƒé›†ï¼šæ­£å¸¸æ ·æœ¬
        image_train_dataset = MultiModalDataset(
            image_paths=image_train_paths,
            transform=transform
        )
        image_train_loader = DataLoader(image_train_dataset, batch_size=batch_size, shuffle=True)

    if image_test_paths and image_test_labels is not None:
        # ä»æµ‹è¯•é›†ä¸­åˆ’åˆ†éªŒè¯é›†å’Œæµ‹è¯•é›†
        # ç¡®ä¿éªŒè¯é›†åŒ…å«æ­£å¸¸æ ·æœ¬å’Œå¼‚å¸¸æ ·æœ¬
        test_indices = list(range(len(image_test_paths)))

        if len(test_indices) > 1:
            # åˆ†å±‚åˆ’åˆ†ï¼Œç¡®ä¿éªŒè¯é›†ä¸­åŒ…å«ä¸¤ç§ç±»åˆ«
            normal_indices = [i for i, label in enumerate(image_test_labels) if label == 0]
            anomaly_indices = [i for i, label in enumerate(image_test_labels) if label == 1]

            # ä¸ºæ¯ç±»åˆ†åˆ«åˆ’åˆ†éªŒè¯é›†
            val_normal_indices = normal_indices[:max(1, int(len(normal_indices) * val_split))]
            val_anomaly_indices = anomaly_indices[:max(1, int(len(anomaly_indices) * val_split))]

            val_indices = val_normal_indices + val_anomaly_indices
            test_indices = [i for i in test_indices if i not in val_indices]

            # åˆ›å»ºéªŒè¯é›†
            image_val_paths = [image_test_paths[i] for i in val_indices]
            image_val_labels = [image_test_labels[i] for i in val_indices]

            # åˆ›å»ºæµ‹è¯•é›†
            image_test_paths_final = [image_test_paths[i] for i in test_indices]
            image_test_labels_final = [image_test_labels[i] for i in test_indices]
        else:
            # æ•°æ®å¤ªå°‘ï¼Œç›´æ¥ä½¿ç”¨å…¨éƒ¨ä½œä¸ºæµ‹è¯•é›†ï¼ŒéªŒè¯é›†ä¸ºç©º
            image_val_paths = []
            image_val_labels = []
            image_test_paths_final = image_test_paths
            image_test_labels_final = image_test_labels

        # åˆ›å»ºéªŒè¯é›†åŠ è½½å™¨
        if image_val_paths:
            image_val_dataset = MultiModalDataset(
                image_paths=image_val_paths,
                transform=transform
            )
            image_val_dataset.labels = image_val_labels
            image_val_loader = DataLoader(image_val_dataset, batch_size=batch_size, shuffle=False)

        # åˆ›å»ºæµ‹è¯•é›†åŠ è½½å™¨
        if image_test_paths_final:
            image_test_dataset = MultiModalDataset(
                image_paths=image_test_paths_final,
                transform=transform
            )
            image_test_dataset.labels = image_test_labels_final
            image_test_loader = DataLoader(image_test_dataset, batch_size=batch_size, shuffle=False)

    # Task4æ•°æ®åŠ è½½å™¨ï¼ˆæ•°å€¼ï¼‰
    numerical_train_loader = None
    numerical_val_loader = None
    numerical_test_loader = None

    if numerical_train_data is not None:
        # è®­ç»ƒé›†ï¼šæ­£å¸¸æ ·æœ¬
        numerical_train_dataset = MultiModalDataset(
            numerical_data=numerical_train_data
        )
        numerical_train_loader = DataLoader(numerical_train_dataset, batch_size=batch_size, shuffle=True)

    if numerical_test_data is not None and numerical_test_labels is not None:
        # ä»æµ‹è¯•é›†ä¸­åˆ’åˆ†éªŒè¯é›†å’Œæµ‹è¯•é›†
        test_indices = list(range(len(numerical_test_data)))

        if len(test_indices) > 1:
            # åˆ†å±‚åˆ’åˆ†ï¼Œç¡®ä¿éªŒè¯é›†ä¸­åŒ…å«ä¸¤ç§ç±»åˆ«
            normal_indices = [i for i, label in enumerate(numerical_test_labels) if label == 0]
            anomaly_indices = [i for i, label in enumerate(numerical_test_labels) if label == 1]

            # ä¸ºæ¯ç±»åˆ†åˆ«åˆ’åˆ†éªŒè¯é›†
            val_normal_indices = normal_indices[:max(1, int(len(normal_indices) * val_split))]
            val_anomaly_indices = anomaly_indices[:max(1, int(len(anomaly_indices) * val_split))]

            val_indices = val_normal_indices + val_anomaly_indices
            test_indices = [i for i in test_indices if i not in val_indices]

            # åˆ›å»ºéªŒè¯é›†
            numerical_val_data = numerical_test_data[val_indices]
            numerical_val_labels = numerical_test_labels[val_indices]

            # åˆ›å»ºæµ‹è¯•é›†
            test_indices_array = np.array(test_indices)
            numerical_test_data_final = numerical_test_data[test_indices_array]
            numerical_test_labels_final = numerical_test_labels[test_indices_array]
        else:
            # æ•°æ®å¤ªå°‘ï¼Œç›´æ¥ä½¿ç”¨å…¨éƒ¨ä½œä¸ºæµ‹è¯•é›†ï¼ŒéªŒè¯é›†ä¸ºç©º
            numerical_val_data = None
            numerical_val_labels = None
            numerical_test_data_final = numerical_test_data
            numerical_test_labels_final = numerical_test_labels

        # åˆ›å»ºéªŒè¯é›†åŠ è½½å™¨
        if numerical_val_data is not None and len(numerical_val_data) > 0:
            numerical_val_dataset = MultiModalDataset(
                numerical_data=numerical_val_data
            )
            numerical_val_dataset.labels = numerical_val_labels
            numerical_val_loader = DataLoader(numerical_val_dataset, batch_size=batch_size, shuffle=False)

        # åˆ›å»ºæµ‹è¯•é›†åŠ è½½å™¨
        if numerical_test_data_final is not None and len(numerical_test_data_final) > 0:
            numerical_test_dataset = MultiModalDataset(
                numerical_data=numerical_test_data_final
            )
            numerical_test_dataset.labels = numerical_test_labels_final
            numerical_test_loader = DataLoader(numerical_test_dataset, batch_size=batch_size, shuffle=False)

    return (image_train_loader, image_val_loader, image_test_loader,
            numerical_train_loader, numerical_val_loader, numerical_test_loader)


def main():
    """ä¸»å‡½æ•°"""
    print("å¤šæ¨¡æ€å¼‚å¸¸æ£€æµ‹Transformeræ¼”ç¤º")
    print("=" * 50)
    print("ä½¿ç”¨ç­–ç•¥ï¼šåŒä¸€ä¸ªæ¨¡å‹åˆ†åˆ«è®­ç»ƒTask2å’ŒTask4")
    print("=" * 50)

    # è§£æå‚æ•°
    args = parse_args()

    # è·å–é…ç½®
    if args.config == 'small':
        model_config, training_config, eval_config = get_small_config()
    elif args.config == 'large':
        model_config, training_config, eval_config = get_large_config()
    else:
        model_config, training_config, eval_config = get_config()

    # è¦†ç›–é…ç½®
    if args.epochs:
        training_config.num_epochs = args.epochs
    if args.batch_size:
        training_config.batch_size = args.batch_size
    if args.quick_test:
        training_config.num_epochs = 3
        model_config.depth = 2

    # è®¾ç½®è®¾å¤‡
    device = setup_device(args.device)

    # åˆ›å»ºå¯è§†åŒ–å™¨
    visualizer = AnomalyVisualizer(args.save_dir)

    try:
        # åŠ è½½æ•°æ®
        data = load_data(training_config)

        # åˆ›å»ºåˆ†åˆ«çš„æ•°æ®åŠ è½½å™¨
        (image_train_loader, image_val_loader, image_test_loader,
         numerical_train_loader, numerical_val_loader, numerical_test_loader) = create_separate_dataloaders(
            *data, batch_size=training_config.batch_size
        )

        # åˆ›å»ºæ¨¡å‹å’Œè®­ç»ƒå™¨
        model, trainer = create_model_and_trainer(model_config, training_config, device)

        # å¦‚æœæŒ‡å®šäº†checkpointï¼ŒåŠ è½½å¹¶ç»§ç»­è®­ç»ƒ
        if args.resume:
            print(f"Loading checkpoint from: {args.resume}")
            checkpoint = torch.load(args.resume, map_location=device, weights_only=False)
            model.load_state_dict(checkpoint['model_state_dict'])

            # å¦‚æœcheckpointåŒ…å«ä¼˜åŒ–å™¨çŠ¶æ€ï¼Œä¹ŸåŠ è½½
            if 'optimizer_state_dict' in checkpoint:
                trainer.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
                print("Optimizer state loaded")

            # å¦‚æœcheckpointåŒ…å«epochä¿¡æ¯ï¼Œæ›´æ–°è®­ç»ƒè½®æ•°
            if 'epoch' in checkpoint:
                start_epoch = checkpoint['epoch'] + 1
                remaining_epochs = training_config.num_epochs - start_epoch
                if remaining_epochs > 0:
                    training_config.num_epochs = remaining_epochs
                    print(f"Resuming from epoch {start_epoch}, remaining {remaining_epochs} epochs")
                else:
                    print(f"Model already trained for {training_config.num_epochs} epochs, finishing training")

            print("Checkpoint loaded successfully")
            print(f"   Model parameters: {sum(p.numel() for p in model.parameters()):,}")

        # åˆ†åˆ«è®­ç»ƒä¸¤ç§ä»»åŠ¡
        train_losses, _ = train_task_separately(
            trainer, image_train_loader, numerical_train_loader,
            image_val_loader, numerical_val_loader,
            training_config.num_epochs, args.save_dir
        )

        # ç»˜åˆ¶è®­ç»ƒå†å²
        visualizer.plot_training_history(train_losses, [])

        # åˆ†åˆ«è¯„ä¼°ä¸¤ç§ä»»åŠ¡
        task_results = evaluate_separate_tasks(
            trainer, image_test_loader, numerical_test_loader,
            visualizer, eval_config.anomaly_threshold_percentile
        )

        # è¾“å‡ºæ€»ç»“ç»“æœ
        print("\nè®­ç»ƒç»“æœæ€»ç»“:")
        print("=" * 30)

        if 'task2' in task_results:
            print("Task2ï¼ˆå›¾åƒå¼‚å¸¸æ£€æµ‹ï¼‰:")


        if 'task4' in task_results:
            print("\nTask4ï¼ˆæ•°å€¼å¼‚å¸¸æ£€æµ‹ï¼‰:")

        # åˆ›å»ºè¯„ä¼°æŠ¥å‘Š
        report_metrics = {
            'depth': model_config.depth,
            'embed_dim': model_config.embed_dim,
            'epochs': training_config.num_epochs,
            'total_train_loss': train_losses[-1] if train_losses else 0.0
        }

        # è®¡ç®—confusion matrixç­‰é¢å¤–ä¿¡æ¯
        def calculate_confusion_matrix(labels, predictions):
            from sklearn.metrics import confusion_matrix
            cm = confusion_matrix(labels, predictions)
            return cm

        # æ·»åŠ è¯„ä¼°ç»“æœ
        if 'task2' in task_results and task_results['task2']:
            task2_data = task_results['task2']
            report_metrics.update({
                'task2_auc': task2_data.get('auc', 'N/A'),
                'task2_precision': task2_data.get('precision', 'N/A'),
                'task2_recall': task2_data.get('recall', 'N/A'),
                'task2_f1': task2_data.get('f1', 'N/A'),
                'task2_accuracy': task2_data.get('accuracy', 'N/A'),
                'task2_threshold': task2_data.get('threshold', 'N/A'),
                'task2_confusion_matrix': calculate_confusion_matrix(task2_data.get('labels', []), task2_data.get('predictions', [])) if 'labels' in task2_data and 'predictions' in task2_data else None
            })

        if 'task4' in task_results and task_results['task4']:
            task4_data = task_results['task4']
            report_metrics.update({
                'task4_auc': task4_data.get('auc', 'N/A'),
                'task4_precision': task4_data.get('precision', 'N/A'),
                'task4_recall': task4_data.get('recall', 'N/A'),
                'task4_f1': task4_data.get('f1', 'N/A'),
                'task4_accuracy': task4_data.get('accuracy', 'N/A'),
                'task4_threshold': task4_data.get('threshold', 'N/A'),
                'task4_confusion_matrix': calculate_confusion_matrix(task4_data.get('labels', []), task4_data.get('predictions', [])) if 'labels' in task4_data and 'predictions' in task4_data else None
            })

        # æ·»åŠ æ•°æ®é›†ä¿¡æ¯
        image_train_count = len(image_train_loader.dataset) if image_train_loader else 0
        image_test_count = len(image_test_loader.dataset) if image_test_loader else 0
        numerical_train_count = len(numerical_train_loader.dataset) if numerical_train_loader else 0
        numerical_test_count = len(numerical_test_loader.dataset) if numerical_test_loader else 0

        report_metrics.update({
            'image_train_samples': image_train_count,
            'image_test_samples': image_test_count,
            'numerical_train_samples': numerical_train_count,
            'numerical_test_samples': numerical_test_count,
            'total_train_samples': image_train_count + numerical_train_count,
            'total_test_samples': image_test_count + numerical_test_count
        })
        visualizer.create_summary_report(report_metrics)

        # ä¿å­˜ç»“æœ
        results = {
            'model': model,
            'task_results': task_results,
            'config': model_config
        }
        save_results(results, training_config, args.save_dir)

        print("\næ¼”ç¤ºå®Œæˆï¼")
        print(f"ç»“æœä¿å­˜åœ¨: {args.save_dir}")
        print("æœ€ä½³æ¨¡å‹å·²ä¿å­˜ä¸º: best_model_checkpoint.pth")

        # æ£€æŸ¥æœ€ä½³æ¨¡å‹æ˜¯å¦å­˜åœ¨å¹¶æ˜¾ç¤ºä¿¡æ¯
        best_model_path = os.path.join(args.save_dir, 'best_model_checkpoint.pth')
        if os.path.exists(best_model_path):
            best_checkpoint = torch.load(best_model_path, map_location='cpu', weights_only=False)
            print(f"æœ€ä½³æ¨¡å‹ä¿¡æ¯:")
            print(f"   - æœ€ä½³epoch: {best_checkpoint.get('epoch', 'N/A')}")
            print(f"   - Task2 AUC: {best_checkpoint.get('best_task2_auc', 'N/A'):.4f}")
            print(f"   - Task4 AUC: {best_checkpoint.get('best_task4_auc', 'N/A'):.4f}")
            print(f"   - ç»„åˆAUC: {best_checkpoint.get('best_combined_auc', 'N/A'):.4f}")

    except Exception as e:
        print(f"å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()