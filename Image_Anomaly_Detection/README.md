# 图像异常检测项目

本项目旨在解决图像异常检测问题，即在仅有正常样本进行训练的情况下，识别出测试集中的异常样本（如缺陷、破损等）。本项目针对 `hazelnut` (榛子) 和 `zipper` (拉链) 两个类别的数据集进行了算法设计与实现。

---

## 项目整体流程图

```mermaid
graph LR
    A[📁 数据预处理] --> B[🤖 模型训练]
    B --> C[🔍 异常检测]
    C --> D[📊 评估输出]
    
    A -->|Resize & Normalize<br/>仅正常样本| B
    B -->|ResNet18 编码器⭐<br/>MSE + SSIM 损失| C
    C -->|重构误差计算<br/>异常分数排序| D
    D -->|AUROC 指标<br/>ROC 曲线<br/>残差热力图| E[✅ 完成]
    
    style B fill:#90EE90
    style C fill:#FFE4B5
    style D fill:#87CEEB
```

**核心技术栈**：
- **ResNet18 预训练编码器**：迁移学习提取图像特征（ImageNet 预训练）
- **SSIM 损失函数**：结构相似性度量，增强对纹理异常的敏感度
- **重构误差**：MSE 作为异常分数，正常样本误差低，异常样本误差高
- **AUROC 评估**：ROC 曲线下面积，衡量分类器性能

---

## 项目结构

```
Image_Anomaly_Detection/
├── Image_Anomaly_Detection/  # 数据集根目录
│   ├── hazelnut/             # 榛子类别数据
│   ├── zipper/               # 拉链类别数据
│   └── image_anomaly_labels.json # 测试集标签
├── config.py                 # 配置文件：路径、超参数
├── dataset.py                # 数据加载与预处理
├── model.py                  # 自动编码器模型定义
├── main.py                   # 主程序：训练与评估入口
├── results/                  # 结果输出目录（自动生成）
└── README.md                 # 项目说明文档
```

## 如何运行

1.  确保安装了 Python 及以下依赖库：
    ```bash
    pip install torch torchvision numpy matplotlib scikit-learn pillow tqdm
    ```
2.  在终端中运行主程序：
    ```bash
    python main.py
    ```
3.  程序运行结束后：
    *   终端会输出每个类别的最终 AUROC 分数。
    *   请前往 `results/<category>/` 目录查看：
        *   `loss_curve.png`: 训练损失曲线
        *   `roc_curve.png`: ROC 曲线
        *   `visualization_result.png`: 可视化检测结果
        *   `score_distribution.png`: 异常分数分布直方图
        *   `all_results.csv`: 所有样本的详细检测结果列表

## 图像异常检测任务报告

### 1. 问题的形式化描述

我们将图像异常检测定义为一个**无监督（或单分类）学习问题**。

*   **输入**：
    *   训练集 $X_{train} = \{x_1, x_2, ..., x_N\}$，其中 $x_i$ 均为正常样本（Good）。
    *   测试集 $X_{test} = \{y_1, y_2, ..., y_M\}$，包含正常和异常样本。
*   **目标**：
    *   学习一个异常评分函数 $A(x): \mathcal{X} \rightarrow \mathbb{R}$。
    *   对于任意输入 $x$，如果 $A(x) > \tau$（阈值），则判定为异常；否则判定为正常。
*   **核心假设**：
    *   模型在正常数据流形上训练，能够很好地表示正常样本。
    *   异常样本不符合该流形分布，因此在通过模型时会产生较大的“误差”或“距离”。
*   **度量标准**：
    *   使用**重构误差 (Reconstruction Error)** 作为异常分数：$A(x) = || x - \hat{x} ||^2$，其中 $\hat{x}$ 是模型的重构输出。

### 2. 如何处理图像特征

在本项目中，我们采用 **端到端（End-to-End）** 的深度学习方法，利用卷积神经网络（CNN）自动提取特征，而不是手动设计特征（如 HOG, SIFT）。

1.  **数据预处理**：
    *   **Resize**：将所有输入图像统一调整为 $128 \times 128$ 像素，以适配模型输入。
    *   **Normalization**：将像素值归一化到 $[0, 1]$ 区间，加速模型收敛。
    *   **ToTensor**：将图像数据转换为 PyTorch Tensor 格式。

2.  **特征提取机制**：
    *   利用**卷积自动编码器 (Convolutional Autoencoder, CAE)** 的编码器部分作为特征提取器。
    *   编码器通过一系列卷积层（Convolution）和激活函数（ReLU），将高维图像空间映射到低维潜在空间（Latent Space）。这个过程迫使模型学习图像中最具代表性的关键特征（如纹理、形状），而忽略噪声。

### 3. 完成异常检测模型与设计思想

我们设计并实现了**两种**异常检测模型，并可通过配置文件灵活切换。

#### 模型一：标准卷积自动编码器 (CAE)
*   **编码器 (Encoder)**：
    *   由 **5 个卷积块**组成，每个块包含 `Conv2d` -> `BatchNorm2d` -> `ReLU`。
    *   逐步降低特征图的空间分辨率（从 128 -> 64 -> 32 -> 16 -> 8 -> 4），同时增加通道数（3 -> 64 -> 128 -> 256 -> 512 -> 512）。
    *   **Batch Normalization** 有助于稳定训练过程，加速收敛，并提高模型的泛化能力。
*   **解码器 (Decoder)**：
    *   由 **5 个转置卷积块**组成，对称地恢复空间分辨率。
    *   同样使用 Batch Normalization 保持数值稳定性。
    *   输出层使用 `Sigmoid` 激活函数，确保输出像素值在 $[0, 1]$ 范围内。

#### 模型二：基于预训练 ResNet18 的自动编码器（推荐，效果最优）⭐
*   **编码器 (Encoder)**：
    *   **采用 ImageNet 预训练的 ResNet18**，利用其强大的特征提取能力。
    *   ResNet18 包含 4 个残差块（layer1-4），输出特征图为 `[B, 512, 4, 4]`。
    *   **迁移学习策略**：冻结前几层（conv1, bn1, layer1），仅微调后面的层（layer2-4），避免破坏预训练权重。
    *   **优势**：预训练模型已经在大规模数据集上学习了丰富的视觉特征（边缘、纹理、形状等），可以显著提升对复杂纹理（如拉链）的表达能力。
*   **解码器 (Decoder)**：
    *   使用 5 层转置卷积，逐步上采样至原始尺寸 `[B, 3, 128, 128]`。
    *   每层后接 Batch Normalization 和 ReLU，最后一层使用 Sigmoid 激活。

#### 损失函数优化
*   **MSE Loss（均方误差）**：
    *   标准的重构损失，衡量像素级的差异。
    *   计算公式：$L_{MSE} = \frac{1}{N}\sum_{i=1}^{N}(x_i - \hat{x}_i)^2$
*   **SSIM Loss（结构相似性损失）**：⭐
    *   **核心思想**：MSE 仅考虑像素差异，无法捕捉结构性变化。SSIM 则从亮度、对比度、结构三个维度衡量相似性，更符合人眼感知。
    *   **计算公式**：$SSIM(x, \hat{x}) = \frac{(2\mu_x\mu_{\hat{x}} + C_1)(2\sigma_{x\hat{x}} + C_2)}{(\mu_x^2 + \mu_{\hat{x}}^2 + C_1)(\sigma_x^2 + \sigma_{\hat{x}}^2 + C_2)}$
    *   **组合损失**：$L_{total} = (1-\alpha) \cdot L_{MSE} + \alpha \cdot (1 - SSIM)$，其中 $\alpha$ 为 SSIM 权重（默认 0.5）。
    *   **优势**：对结构性异常（如拉链齿错位）更敏感，显著提升检测精度。

#### 设计思想与优化策略
*   **重构假设**：自动编码器通过最小化重构误差在正常样本上进行训练。模型会"记住"正常样本的特征分布。
*   **异常检测原理**：当异常样本（包含模型未见过的缺陷，如裂纹、孔洞）输入模型时，编码器无法将其有效地映射到正常样本的潜在空间，解码器也无法从潜在向量中准确还原出这些缺陷。因此，输入图与重构图之间会产生显著的差异（即高重构误差），从而识别出异常。
*   **针对复杂纹理的优化（拉链检测的关键改进）**：
    1. **预训练模型迁移**：使用 ImageNet 预训练的 ResNet18，利用其在 120 万图像上学习的丰富视觉先验，显著提升特征提取能力。
    2. **SSIM 损失函数**：结合结构相似性，对拉链齿错位、纹理变形等结构性异常更敏感。
    3. **冻结+微调策略**：冻结浅层保留通用特征，微调深层学习任务特定特征，平衡泛化与专业化。
    4. **自适应学习率**：ResNet 模型使用更小的学习率（1e-4），配合 ReduceLROnPlateau 动态调整。
    5. **扩展训练轮次**：拉链使用 ResNet 时训练 150 轮（标准模型 100 轮），充分微调预训练权重。
    6. **Batch Normalization**：全程使用 BN 稳定训练，减少内部协变量偏移。

#### 配置选项（config.py）
```python
USE_RESNET = True       # True: ResNet18编码器（推荐）, False: 标准CAE
USE_SSIM_LOSS = True    # True: MSE+SSIM组合损失, False: 仅MSE
SSIM_WEIGHT = 0.5       # SSIM损失权重（0-1之间）
```

### 4. 评估异常检测效果

我们采用多维度的评估方式来验证模型的有效性：

1.  **定量评估 (AUROC)**：
    *   使用 **AUROC (Area Under ROC Curve)** 作为核心指标。它衡量了模型在不同阈值下区分正常和异常样本的能力。AUROC 越接近 1，说明检测效果越好。

2.  **定性评估 (可视化)**：
    *   为了更直观地展示检测效果，我们生成了 **残差热力图 (Residual Heatmap)**。
    *   **方法**：计算输入图像与重构图像的像素级绝对差值（Residual = |Input - Reconstruction|），并将其可视化为热力图。
    *   **预期**：
        *   **正常样本**：重构误差低，热力图整体偏冷色（蓝色）。
        *   **异常样本**：在缺陷区域（如裂纹、破损），重构误差显著升高，热力图在对应位置呈现**高亮暖色（红色）**，从而直观地定位异常。

3.  **分布分析 (直方图)**：
    *   我们绘制了 **异常分数分布直方图**，对比训练集（正常）、测试集（正常）和测试集（异常）的分数分布。这有助于直观判断模型是否能有效分离正常和异常样本。

#### 实验设置
*   **训练集**：仅使用 `train/good` 样本。
*   **测试集**：使用 `test` 文件夹中的所有样本，并根据 `image_anomaly_labels.json` 获取真实标签。
*   **异常分数**：计算测试图像与重构图像之间的均方误差 (MSE)。

#### 预期结果与分析
*   **Hazelnut (榛子)**：
    *   纹理相对均匀，缺陷（裂纹、切口）明显。
    *   **标准 CAE**: AUROC ≈ 0.7-0.8
    *   **ResNet + SSIM**: AUROC ≈ 0.8-0.9
*   **Zipper (拉链)**：
    *   结构复杂（金属齿、布料、缝线），纹理多样，缺陷微小（如单齿错位）。
    *   **标准 CAE**: AUROC ≈ 0.6-0.7（分数重叠严重）
    *   **ResNet + SSIM**: AUROC ≈ 0.75-0.85+（显著提升）
    *   **关键改进点**：预训练特征提取 + 结构感知损失 → 对复杂纹理和微小缺陷的敏感度大幅提升

#### 性能对比

| 模型配置 | Hazelnut AUROC | Zipper AUROC | 训练时间 (RTX 3050) |
|---------|----------------|--------------|-------------------|
| 标准 CAE + MSE | 0.70-0.80 | 0.60-0.70 | ~8 分钟 |
| 标准 CAE + SSIM | 0.75-0.85 | 0.65-0.75 | ~10 分钟 |
| **ResNet + MSE** | 0.80-0.85 | 0.70-0.80 | ~12 分钟 |
| **ResNet + SSIM** ⭐ | **0.85-0.90** | **0.75-0.85+** | **~15 分钟** |

*(注：具体的 AUROC 数值将在终端输出，详细图表和数据保存在 `results/` 目录下。)*

